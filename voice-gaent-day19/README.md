# ğŸ™ï¸ Voice Agent - AI-Powered Speech-to-Speech Platform

A professional, real-time speech-to-speech interaction platform built with FastAPI that enables natural voice conversations with AI through a complete pipeline: Speech-to-Text â†’ LLM Processing â†’ Text-to-Speech.

## ğŸ“¸ Screenshots

_Main Interface_
![Main Interface](screenshots/main.png)

_AI Conversation_
![AI Conversation](screenshots/thinking.png)
![AI Conversation](screenshots/response.png)

_Reset_
![Reset](screenshots/reset.png)

## ğŸŒŸ Core Features

### Speech-to-Speech Pipeline

-   **ğŸ¤ Voice Input** - Real-time browser audio capture with WebAudio API
-   **ğŸ“ Speech-to-Text** - High-accuracy transcription via AssemblyAI
-   **ğŸ¤– AI Processing** - Intelligent responses using Google Gemini AI
-   **ğŸ”Š Text-to-Speech** - Natural voice synthesis with Murf AI
-   **ğŸ§ Audio Output** - Seamless playback in browser

### Advanced Capabilities

-   **ğŸ’¬ Conversational Memory** - Maintains context across conversation turns
-   **ğŸ“± Responsive UI** - Works perfectly on desktop and mobile devices
-   **ğŸ”„ Session Management** - Persistent conversations with unique session IDs
-   **âš¡ Real-time Processing** - Optimized pipeline for low-latency responses
-   **ğŸ›¡ï¸ Robust Error Handling** - Graceful fallbacks when services are unavailable

## ğŸ—ï¸ Architecture

### Modular Design

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Browser   â”‚â”€â”€â”€â”€â”‚   FastAPI    â”‚â”€â”€â”€â”€â”‚   AI Services   â”‚
â”‚  (WebAudio) â”‚    â”‚   Backend    â”‚    â”‚   (STT/LLM/TTS) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                   â”‚                      â”‚
       â–¼                   â–¼                      â–¼
   Audio Input  â”€â”€â”€â”€>  Processing  â”€â”€â”€â”€>   Audio Output
```

### Speech-to-Speech Workflow

1. **ğŸ¤ Capture** â†’ User records voice through browser
2. **ğŸ“¤ Upload** â†’ Audio sent to FastAPI backend via `/agent/chat/{session_id}`
3. **ğŸ“ Transcribe** â†’ AssemblyAI converts speech to text
4. **ğŸ§  Process** â†’ Gemini AI generates intelligent response with conversation context
5. **ğŸ”Š Synthesize** â†’ Murf AI converts response to natural speech
6. **ğŸ§ Playback** â†’ Audio response streamed back to browser

## ğŸ› ï¸ Technology Stack

### Backend Architecture

-   **FastAPI 2.0** - Modern async web framework with automatic API documentation
-   **Uvicorn** - High-performance ASGI server
-   **Python 3.12+** - Latest Python with enhanced performance
-   **Pydantic** - Data validation and serialization

### AI & Audio Services

-   **AssemblyAI** - Enterprise-grade speech-to-text transcription
-   **Google Gemini 1.5 Flash** - Advanced language model for conversations
-   **Murf AI** - Professional text-to-speech synthesis
-   **Session Management** - In-memory conversation state management

### Frontend Technology

-   **Tailwind CSS** - Modern utility-first styling framework
-   **Vanilla JavaScript** - WebAudio API integration for recording/playback
-   **Responsive Design** - Mobile-first approach with smooth animations

## ğŸ“ Project Structure

```
FastAPI/
â”œâ”€â”€ ğŸ“„ main.py                            # FastAPI application entry point
â”œâ”€â”€ ğŸ“ app/                               # Main application package
â”‚   â”œâ”€â”€ ğŸ“ api/                           # API endpoint modules
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ agent.py                   # Speech-to-speech chat endpoints
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ health.py                  # System health monitoring
â”‚   â”‚   â””â”€â”€ ğŸ“„ legacy.py                  # Backward compatibility
â”‚   â”œâ”€â”€ ğŸ“ core/                          # Core functionality
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ logging.py                 # Logging configuration
â”‚   â”‚   â””â”€â”€ ğŸ“„ config.py                  # Environment configuration
â”‚   â”œâ”€â”€ ğŸ“ models/                        # Data models
â”‚   â”‚   â””â”€â”€ ğŸ“„ schemas.py                 # Pydantic request/response models
â”‚   â””â”€â”€ ğŸ“ services/                      # Business logic services
â”‚       â”œâ”€â”€ ğŸ“„ stt_service.py             # Speech-to-Text service
â”‚       â”œâ”€â”€ ğŸ“„ llm_service.py             # Language model service
â”‚       â”œâ”€â”€ ğŸ“„ tts_service.py             # Text-to-Speech service
â”‚       â”œâ”€â”€ ğŸ“„ session_service.py         # Conversation management
â”‚       â””â”€â”€ ğŸ“„ health_service.py          # System monitoring
â”œâ”€â”€ ğŸ“ templates/                         # HTML templates
â”‚   â””â”€â”€ ğŸ“„ index.html                     # Main web interface
â”œâ”€â”€ ğŸ“ static/                            # Frontend assets
â”‚   â”œâ”€â”€ ğŸ“„ script.js                      # Application JavaScript
â”‚   â””â”€â”€ ğŸ“„ styles.css                     # Additional styling
â””â”€â”€ ğŸ“„ requirements.txt                   # Python dependencies
```

## ğŸš€ Quick Start

### Prerequisites

-   Python 3.12 or higher
-   Valid API keys for all services

### Installation

```bash
# Clone the repository
git clone https://github.com/HsAhRaSrHmIaT/FastAPI-Murf.git
cd FastAPI

# Install dependencies
pip install -r requirements.txt
```

### Environment Setup

Create a `.env` file in the root directory:

```env
# Required API Keys
GOOGLE_API_KEY=your_gemini_api_key_here
MURF_API_KEY=your_murf_api_key_here
MURF_API_URL=your_murf_api_url_here
ASSEMBLYAI_API_KEY=your_assemblyai_api_key_here
```

### Run the Application

```bash
# Start the development server
python main.py

# Or use uvicorn directly
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

Visit `http://localhost:8000` to start your voice conversations! ğŸ™ï¸

## ğŸ”§ API Endpoints

### Core Speech-to-Speech

| Endpoint                           | Method | Description                        |
| ---------------------------------- | ------ | ---------------------------------- |
| `/`                                | GET    | Main web interface                 |
| `/agent/chat/{session_id}`         | POST   | Complete speech-to-speech pipeline |
| `/agent/chat/{session_id}/history` | GET    | Get conversation history           |
| `/agent/chat/{session_id}`         | DELETE | Clear conversation history         |

### System Monitoring

| Endpoint              | Method | Description                   |
| --------------------- | ------ | ----------------------------- |
| `/health/`            | GET    | System health status          |
| `/health/test-errors` | GET    | Test error scenarios          |
| `/docs`               | GET    | Interactive API documentation |

### Legacy Support

| Endpoint           | Method | Description         |
| ------------------ | ------ | ------------------- |
| `/generate-speech` | POST   | Text-to-speech only |
| `/upload`          | POST   | Speech-to-text only |
| `/llm/query`       | POST   | LLM processing only |

## ğŸ¯ Key Features Deep Dive

### Conversation Intelligence

-   **Context Awareness** - Maintains conversation history for natural flow
-   **Error Recovery** - Continues conversation even if individual services fail
-   **Session Isolation** - Multiple users can have independent conversations

### Audio Processing

-   **High-Quality Recording** - WebAudio API with noise suppression
-   **Multiple Formats** - Supports WAV, MP3, WebM, OGG, MP4
-   **Optimized Pipeline** - Efficient audio processing and streaming

### User Experience

-   **Real-time Feedback** - Visual indicators for recording, processing, and playback
-   **Responsive Design** - Seamless experience across all devices
-   **Accessibility** - Keyboard navigation and screen reader support

## ğŸ”§ Service Architecture

### STT Service (`stt_service.py`)

-   Handles audio file processing and transcription
-   Integrates with AssemblyAI for accurate speech recognition
-   Supports multiple audio formats with automatic conversion

### LLM Service (`llm_service.py`)

-   Manages conversation context and AI responses
-   Integrates with Google Gemini 1.5 Flash model
-   Implements conversation memory for natural interactions

### TTS Service (`tts_service.py`)

-   Converts text responses to natural speech
-   Integrates with Murf AI for high-quality voice synthesis
-   Handles audio streaming and format optimization

### Session Service (`session_service.py`)

-   Manages conversation state across requests
-   Implements in-memory session storage
-   Provides conversation history and cleanup

### Health Service (`health_service.py`)

-   Monitors all external service availability
-   Provides detailed health status reporting
-   Enables graceful degradation on service failures

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/amazing-feature`
3. Make your changes with proper testing
4. Commit: `git commit -m 'Add amazing feature'`
5. Push: `git push origin feature/amazing-feature`
6. Open a Pull Request


---

**Built with modern AI services and web technologies for seamless voice interactions**

_Refactored Architecture - Production Ready_ ğŸš€
